VALSE 2020视觉与学习青年学者研讨会

《机器学习前沿进展》

田渊栋博士《深度ReLU网络中可证明的理论性质》





神经网络的理论研究有三个的方向

1. 第一个是可表达性（Expressibility）：神经网络能多大程度上拟合函数-只要有一层无限神经元的隐层，神经网络就能拟合任何函数
2. 





ReLU

因为它很容易实现，而且学习比较快，能自然地实现网络稀疏性。除此之外，它还有一些非常有趣的理论性质，并且它的函数性质对理论分析来说有好处。当然，它也有不足的地方，比如说不可微的、不可逆，存在参数化奇点等。



