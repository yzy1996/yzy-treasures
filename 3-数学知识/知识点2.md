# Convolution（卷积）

arithmetic understanding guide-[link](https://github.com/vdumoulin/conv_arithmetic)

We should know about **standard convolution** and **dilated convolution（空洞卷积）**





# end-to-end learning

using a neural network to connect input and output.(One example is Attention)

combine all the section models

it used to get the feature manually, but now use the end-to-end to auto learn the features.

**end-to-end 的本质是你要解决的问题是多阶段的或多步的(跟所谓的raw feature没啥关系)。如果分阶段学习的话，第一阶段的最优解不能保证第二阶段的问题达到最优。end-to-end把他们堆在一起来优化，确保最后阶段的解达到最优**



# one/zero-shot learning




they all both belong to transfer learning(迁移学习)，只有一个标注样本的迁移任务被称为一次学习，没有标注样本的迁移任务被称为零次学习。 One-shot learning 指的是我们在训练样本很少，甚至只有一个的情况下，依旧能做预测。

# fully-connected networks全连接网络



# skip connections


